## Multimodal Analysis

This project allows the user to perform a multimodal analysis for emotion recognition in Spanish-language videos. It uses pre-trained models to predict feelings and emotions in different data sources.

The models have been evaluated using a cross validation with a maximum accuracy of 0.8014 when the three modalities (text, audio, video) are combined.
